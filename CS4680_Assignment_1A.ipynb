{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C1X7HoVS78-w"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing kagglehub dataset\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"uciml/sms-spam-collection-dataset\")\n",
        "\n",
        "#identifying path to csv file\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA5eoYZJ80Nf",
        "outputId": "59326185-4495-4066-9647-47940da03709"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'sms-spam-collection-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/sms-spam-collection-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the csv file\n",
        "df = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', encoding=\"latin-1\")[[\"v1\", \"v2\"]]\n",
        "df.columns = [\"label\", \"message\"] #labeling the contents of the data with column 1 = spam/ham identifier and column 2 = message\n",
        "\n",
        "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1}) #converting text values to boolean values for better training\n",
        "\n",
        "#Split data into random train and test subsets. 20% will be utilized for testing 80% for training; random_state used to control shuffling to allow the same result of shuffling every time.\n",
        "X_train, X_test, y_train, y_test = train_test_split( df[\"message\"], df[\"label\"], test_size=0.2, random_state=42)\n",
        "\n",
        "#uses TfidfVectorizer to convert data text to a matrix of TF-IDF features.\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7) #remove stopwords and words that have higher document frequency than 0.7\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train) #Learn vocabulary and idf\n",
        "X_test_tfidf = vectorizer.transform(X_test) #transform testing data to document frequencies\n",
        "\n",
        "#Train logistic regression classifier on the TF-IDF features.\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "#predicions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "#printing prediction results\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmAY6iMj9JnB",
        "outputId": "751fb25a-a084-40dc-a6c9-a15b5aca90e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       965\n",
            "           1       0.97      0.67      0.79       150\n",
            "\n",
            "    accuracy                           0.95      1115\n",
            "   macro avg       0.96      0.83      0.88      1115\n",
            "weighted avg       0.95      0.95      0.95      1115\n",
            "\n",
            "Confusion Matrix:\n",
            " [[962   3]\n",
            " [ 50 100]]\n"
          ]
        }
      ]
    }
  ]
}